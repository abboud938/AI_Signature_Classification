{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.enable_debug_mode()\n",
    "def process_image(image_path):\n",
    "  image = tf.io.read_file(image_path)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image , [224,224])\n",
    "  image = tf.cast(image, tf.float32) / 255.0\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Loading the Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataset = tf.data.Dataset.list_files(\"/content/drive/MyDrive/Denoising_AutoEncoder/Train/augmented/*/*\",shuffle=False)\n",
    "augmented_dataset = augmented_dataset.map(process_image)\n",
    "augmented_train_dataset = augmented_dataset.take(int(0.8 * len(augmented_dataset)))\n",
    "augmented_val_dataset = augmented_dataset.skip(int(0.8 * len(augmented_dataset)))\n",
    "clean_dataset = tf.data.Dataset.list_files(\"/content/drive/MyDrive/Denoising_AutoEncoder/Train/original/*/*\",shuffle=False)\n",
    "clean_dataset = clean_dataset.map(process_image)\n",
    "clean_train_dataset = clean_dataset.take(int(0.8 * len(clean_dataset)))\n",
    "clean_val_dataset = clean_dataset.skip(int(0.8 * len(clean_dataset)))\n",
    "\n",
    "train_set = tf.data.Dataset.zip(augmented_train_dataset,clean_train_dataset).shuffle(5, seed=123).repeat(3).batch(32)\n",
    "val_set = tf.data.Dataset.zip(augmented_val_dataset,clean_val_dataset).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Use SSIM and PSNR Metrics to evaluate the accuracy of the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM(y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "def PSNR(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Buiding the Encoder-Decoder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder(input_shape=(224,224,3), num_layers = 4, num_filters = 64):\n",
    "\n",
    "  input = layers.Input(shape=input_shape)\n",
    "  x = input\n",
    "\n",
    "  # Encoder\n",
    "  for i in range(num_layers):\n",
    "    x = layers.Conv2D(num_filters, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Conv2D(num_filters, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    num_filters = num_filters * 2\n",
    "\n",
    "  x = layers.Dropout(0.2)(x)\n",
    "\n",
    "  # Decoder\n",
    "  for i in range(num_layers):\n",
    "    num_filters = num_filters //2\n",
    "    x = layers.Conv2DTranspose(num_filters, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "  x = layers.Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "  # Autoencoder\n",
    "  autoencoder = Model(input, x, name=\"autoencoder\")\n",
    "\n",
    "  initial_learning_rate = 0.001\n",
    "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.80,\n",
    "    staircase=False)\n",
    "\n",
    "  autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[PSNR, tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), SSIM])\n",
    "  return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = get_autoencoder(num_layers=4)\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_set = train_set.prefetch(buffer_size=AUTOTUNE)\n",
    "val_set = val_set.prefetch(buffer_size=AUTOTUNE)\n",
    "history = ae.fit(train_set , epochs=40 ,validation_data= val_set)\n",
    "ae.save('path_to_save_the_autoencoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prediction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAE = tf.keras.models.load_model('path_to_load_the_autoencoder')\n",
    "image = process_image(\"path_to_denoise_the_signature'\")\n",
    "image = np.expand_dims(image , axis=0)\n",
    "print(image.shape)\n",
    "res = DAE.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
